name: Build

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

env:
  DOCKER_HOSTNAME: ghcr.io
  DOCKER_USERNAME: the-mesh-for-data

jobs:
  build:
    name: Build Spark
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
        - SPARK_VERSION: 2.4.7
          JAVA_VERSION: 1.8
          PROFILE: spark2
          TAG: latest
        - SPARK_VERSION: 3.0.2
          JAVA_VERSION: 11
          PROFILE: spark3
          TAG: latest-spark3
    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK ${{ matrix.JAVA_VERSION }}
        uses: actions/setup-java@v2
        with:
          distribution: 'adopt'
          java-version: ${{ matrix.JAVA_VERSION }}
      - name: Cache Maven packages
        uses: actions/cache@v2.1.4
        with:
          path: |
            docker_images
            ~/.m2/repository
            ~/.zinc
            ~/.sbt
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}-docker${{ hashFiles('src/main/docker/spark/*') }}-${{ matrix.PROFILE }}
#          restore-keys: ${{ runner.os }}-m2
      - name: Build and test jars
        run: mvn -B package -Plocal-to-ghcr -P${{ matrix.PROFILE }}
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v1
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: ${{ matrix.PROFILE }}
          env_vars: SPARK_VERSION
          fail_ci_if_error: true
          path_to_write_report: codecov_report.txt
          verbose: true
      - name: Debug
        run: ls -la docker_images || true
      - name: Recover Spark image from cache
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        run: ci/load_spark_base_cache.sh
      - name: Build Spark base image
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        run: docker build -t spark-base:${{ matrix.SPARK_VERSION }} -f src/main/docker/spark/${{ matrix.PROFILE }}.Dockerfile src/main/docker/spark --cache-from spark-base:${{ matrix.SPARK_VERSION }}
      - name: Save Spark image to cache
        env:
          SPARK_VERSION: ${{ matrix.SPARK_VERSION }}
        run: ci/store_spark_base_cache.sh
      - name: Build docker image with jib
        run: mvn -B jib:dockerBuild -Plocal-to-ghcr -P${{ matrix.PROFILE }}
      - name: Docker login
        if: ${{ github.event_name != 'pull_request' }}
        run: echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ env.DOCKER_USERNAME }}" --password-stdin "${{ env.DOCKER_HOSTNAME }}"
      - name: Docker push
        if: ${{ github.event_name != 'pull_request' }}
        run: docker push ghcr.io/the-mesh-for-data/mover:${{ matrix.TAG }}
